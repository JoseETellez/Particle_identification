{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c3c836f",
   "metadata": {},
   "source": [
    "# Particle identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e68f0f",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b215ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# TensorFlow / Keras Libraries\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os,re\n",
    "import random\n",
    "from PIL import Image \n",
    "\n",
    "# TensorFlow / Keras Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers. normalization import BatchNormalization\n",
    "\n",
    "#Plotting Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#SKLearn Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Garbage Collect\n",
    "import gc\n",
    "\n",
    "#Show Progress Library\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24475628",
   "metadata": {},
   "source": [
    "### Define Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c7c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Directory Path\n",
    "train_images = '../input/baldclassificationselected/data/input/BaldClassification/'\n",
    "test_images = '../input/baldclassificationselected/data/input/BaldClassification/test/'\n",
    "csv_files = '../input/baldclassificationselected/data/input/BaldClassification/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2be8ce",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453932dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Training Data\n",
    "trainData_url = f'{csv_files}/train.csv'\n",
    "train_data = pd.read_csv(trainData_url, header='infer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab1cc23",
   "metadata": {},
   "source": [
    "#### Note: Creating a Test_Data dataframe from the Test Image (test_images) folder. The only reason for doing this is because the files (image_path column) in the test.csv are not in the same order as the files in test folder. And since we are going to use the test folder as our test-dataset to validate the model, it is only logical to use it for creating the dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b6f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Test-Data (image names) from test-folder\n",
    "test_d = []\n",
    "for subdir, dirs, files in os.walk(test_images):\n",
    "    for f in files:\n",
    "        test_d.append(f)\n",
    "\n",
    "test_data = pd.DataFrame(test_d, columns= [\"TestData\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c132acd",
   "metadata": {},
   "source": [
    "### Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a917c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for records\n",
    "print(\"Total Records in Training Dataset: \", train_data.shape[0])\n",
    "print(\"Total Records in Testing Dataset: \", test_data.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4df2273",
   "metadata": {},
   "source": [
    "Total Records in Training Dataset:  6720\n",
    "Total Records in Testing Dataset:  2729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f53931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for null values\n",
    "print(\"Null/Missing Values in Training Dataset: \",train_data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0c1421",
   "metadata": {},
   "source": [
    "Null/Missing Values in Training Dataset:  image_path    0\n",
    "label         0\n",
    "dtype: int64\n",
    "\n",
    "#### Conclusion: There are no null/missing values¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa5ef3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for total labels in Training Dataset\n",
    "train_data.groupby('label').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e00dc1",
   "metadata": {},
   "source": [
    "label\n",
    "0    3360\n",
    "1    3360\n",
    "dtype: int64\n",
    "\n",
    "#### This appears to be an equally distributed \"Binary Classified\" dataset, where 0 = Not Bald & 1 = Is Bald. We will build a model that will return the 'label' of a given test image. But before that, We will have to load & pre-process the train image data¶\n",
    "\n",
    "## Load Images¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf8f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Train Images \n",
    "train_image = []\n",
    "for i in tqdm(range(train_data.shape[0])):\n",
    "    img = image.load_img(f'{train_images}' + train_data['image_path'][i],target_size=(150,150,3))\n",
    "    img = image.img_to_array(img)\n",
    "    #img = img/255 \n",
    "    train_image.append(img)\n",
    "    \n",
    "#Array of Training Images    \n",
    "training_images = np.array(train_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cd5be8",
   "metadata": {},
   "source": [
    "100%|██████████| 6720/6720 [00:26<00:00, 249.18it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef0683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Test Images\n",
    "test_image = []\n",
    "for i in tqdm(range(test_data.shape[0])):\n",
    "    img = image.load_img(f'{test_images}' + test_data['TestData'][i],target_size=(150,150,3))\n",
    "    img = image.img_to_array(img)\n",
    "   # img = img/255 \n",
    "    test_image.append(img)\n",
    "    \n",
    "#Array of Training Images    \n",
    "testing_images = np.array(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c99127",
   "metadata": {},
   "source": [
    "100%|██████████| 2729/2729 [00:10<00:00, 253.56it/s]\n",
    "\n",
    "## Scaling images\n",
    "Note: Its always a best practice to scale the images before feeding to neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f0b7c84",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m training_images \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_images\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m      3\u001b[0m testing_images \u001b[38;5;241m=\u001b[39m testing_images \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_images' is not defined"
     ]
    }
   ],
   "source": [
    "training_images = training_images / 255.0\n",
    "\n",
    "testing_images = testing_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73086516",
   "metadata": {},
   "source": [
    "## Explore Images¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c28372f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#Visualize a random image from training image array\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[43mrandom_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m, in \u001b[0;36mrandom_img\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandom_img\u001b[39m():\n\u001b[1;32m----> 5\u001b[0m     fig \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplots_adjust(hspace \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m)\n\u001b[0;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m221\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#Visualizing a random image\n",
    "\n",
    "def random_img():\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.subplots_adjust(hspace = 0.9)\n",
    "    \n",
    "    plt.subplot(221)\n",
    "    ax1 = plt.imshow(training_images[random.randint(0, 6720)])\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Random Image from Training set\", fontsize=12)\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.subplot(222)\n",
    "    ax2 = plt.imshow(testing_images[random.randint(0, 2729)])\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Random Image from Testing set\", fontsize=12)\n",
    "    plt.grid(False)\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "#Visualize a random image from training image array\n",
    "random_img()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d0de5e",
   "metadata": {},
   "source": [
    "### Define Target\n",
    "In this step, we are going to define the target which is the label column in the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22a01ea9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m training_trgt \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray(train_data\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m'\u001b[39m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Records in Training Target Dataset: \u001b[39m\u001b[38;5;124m\"\u001b[39m, training_trgt\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "training_trgt = np.array(train_data.drop('image_path',axis=1))\n",
    "\n",
    "print(\"Total Records in Training Target Dataset: \", training_trgt.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e6df27",
   "metadata": {},
   "source": [
    "Total Records in Training Target Dataset:  6720\n",
    "\n",
    "### Build Model\n",
    "Building the neural network requires configuring the layers of the model, then compiling the model. The basic building block of a neural network is the layer. Layers extract representations from the data fed into them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e43fb73",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m()\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv2D(\u001b[38;5;241m32\u001b[39m, kernel_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m3\u001b[39m)))\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "#model = keras.models.load_model(\"../input/output/ImgClassificationModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec00a6c2",
   "metadata": {},
   "source": [
    "### Compile Model¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5448f150",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnadam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer='nadam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78254ae6",
   "metadata": {},
   "source": [
    "### Train Model¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d16ef05f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Training the model on training data i.e. Training Images & Training Labels aka Target\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfit(training_images, training_trgt, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#Training the model on training data i.e. Training Images & Training Labels aka Target\n",
    "model.fit(training_images, training_trgt, batch_size = 50, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa3d08",
   "metadata": {},
   "source": [
    "### Making Predictions (with Test Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ab90cbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Predicting Labels\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m predictions_class \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict_classes(testing_images)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Predicting Values\u001b[39;00m\n\u001b[0;32m      4\u001b[0m predictions_val \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(testing_images)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#Predicting Labels\n",
    "predictions_class = model.predict_classes(testing_images)\n",
    "#Predicting Values\n",
    "predictions_val = model.predict(testing_images)\n",
    "\n",
    "#Storing the Predicted Labels & Values to Test Dataset\n",
    "test_data['Predictions'] = predictions_class\n",
    "test_data['PredVals'] = predictions_val.tolist()\n",
    "\n",
    "def display_random_prediction():\n",
    "    \n",
    "    class_names = ['Bald','Not Bald']  # Define the Class Names for Binary Classification \n",
    "    \n",
    "    index = np.random.randint(test_data.shape[0])   #Randomly generating an index number\n",
    "    \n",
    "   \n",
    "    fn = test_data.TestData[index]      #Storing the filename for randomly generated index\n",
    "    lb = test_data.Predictions[index]   #Storing the Predictions for randomly generated index\n",
    "\n",
    "\n",
    "    \n",
    "    #Load Image\n",
    "    test_img = image.load_img(f'{test_images}' + fn,target_size=(150,150,3))\n",
    "    test_img = image.img_to_array(test_img)\n",
    "    test_img = test_img/255.0\n",
    "    \n",
    "    #Plot Image\n",
    "    plt.figure()\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(test_img)\n",
    "    \n",
    "    # Add the image to a batch where it's the only member.\n",
    "    test_img = (np.expand_dims(test_img,0))\n",
    "\n",
    "    # Make Prediction on the singl image\n",
    "    pred_single_val = model.predict(test_img)\n",
    "    pred_single_lb = np.argmax(pred_single_val[0])\n",
    "    \n",
    "    #print(\"value: \",pred_single_val, \"----\", \"class:\",pred_single_class)\n",
    "    \n",
    "\n",
    "    #Plot Title with Prediction\n",
    "    plt.title(\"{} - {:2.1f}%\".format(class_names[pred_single_lb], 100*np.max(pred_single_val) ), fontsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a56b91f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'display_random_prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdisplay_random_prediction\u001b[49m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'display_random_prediction' is not defined"
     ]
    }
   ],
   "source": [
    "display_random_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a249874f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8605376e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e89ac8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246db05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a62bc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
